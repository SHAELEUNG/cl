{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5b2497b3-60ee-7cd0-0625-f103214c0ed4"
   },
   "source": [
    "A piece of text usually conveys an author's attitude towards a certain topic. This can be positive, negative, or neutral (e.g. Reviews on Amazon, IMDB, RottenTomatoes, etc.). Sentiment Analysis tries to infer the *sentiment* via computational modelling of text. \n",
    "\n",
    "- In this tutorial, we will build a simple LSTM model to perform sentiment classification.\n",
    "\n",
    "(Note that this tutorial is largely inspired by https://www.kaggle.com/ngyptr/lstm-sentiment-analysis-keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "39c44f0e-d62c-7e11-a542-4fcd58e21442"
   },
   "source": [
    "#### Load necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might need to install pandas (data/table processing library) before starting this tutorial\n",
    "> pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "6c53202d-5c34-4859-e7e9-8ef5c7068287"
   },
   "outputs": [],
   "source": [
    "# This is a regex library. Regex stands for (reg)ular (ex)pression. \n",
    "# This lets you manipulate string in a very smart&convenient way.\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "6c53202d-5c34-4859-e7e9-8ef5c7068287"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-beadeae2dc6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Libraries for text mipulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# Data processing libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# Libraries for text mipulation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Libraries for building deep learning model. \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "# Libraries to perform standard machine learing training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2bc2702e-d6f4-df5f-b80e-50ab23a6d29e"
   },
   "source": [
    "### Data Loading and Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this exercise, we will use dataset which contains tweets about First GOP Debate 2016. \n",
    "\n",
    "- The original source says: *We looked through tens of thousands of tweets about the early August GOP debate in Ohio and asked contributors to do both sentiment analysis and data categorization. Contributors were asked if the tweet was **relevant**, which **candidate** was mentioned, what **subject** was mentioned, and then what the **sentiment** was for a given tweet. We've removed the non-relevant messages from the uploaded dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "89c8c923-c0bf-7b35-9ab8-e63f00b74e5a"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's familiarise ourselves with data! \n",
    "Sentiment.csv is a dataset in the form of a table, where:\n",
    "- Each row corresponds to one item (tweet1, tweet2, ...) \n",
    "- Each column corresponds to specific attribute ('tweet_id', 'tweet_name', 'subject', 'sentiment', etc..) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 13871 entries and each entry has 21 fields\n"
     ]
    }
   ],
   "source": [
    "# get the number of entries, and the number of fields per entry\n",
    "n_entries, n_fields = data.shape\n",
    "\n",
    "print('The dataset has {} entries and each entry has {} fields'.format(n_entries, n_fields))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view first entry to see how the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                           1\n",
       "candidate                                               No candidate mentioned\n",
       "candidate_confidence                                                         1\n",
       "relevant_yn                                                                yes\n",
       "relevant_yn_confidence                                                       1\n",
       "sentiment                                                              Neutral\n",
       "sentiment_confidence                                                    0.6578\n",
       "subject_matter                                               None of the above\n",
       "subject_matter_confidence                                                    1\n",
       "candidate_gold                                                             NaN\n",
       "name                                                                I_Am_Kenzi\n",
       "relevant_yn_gold                                                           NaN\n",
       "retweet_count                                                                5\n",
       "sentiment_gold                                                             NaN\n",
       "subject_matter_gold                                                        NaN\n",
       "text                         RT @NancyLeeGrahn: How did everyone feel about...\n",
       "tweet_coord                                                                NaN\n",
       "tweet_created                                        2015-08-07 09:54:46 -0700\n",
       "tweet_id                                                    629697200650592256\n",
       "tweet_location                                                             NaN\n",
       "user_timezone                                                            Quito\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas, it is easy to extract the only entries that you care about, as follows. The following code first extracts the relevant *columns*, then views first 5 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>I_Am_Kenzi</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>PeacefulQuest</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>PussssyCroook</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>MattFromTexas31</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>sharonDay5</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                candidate             name  \\\n",
       "0  No candidate mentioned       I_Am_Kenzi   \n",
       "1            Scott Walker    PeacefulQuest   \n",
       "2  No candidate mentioned    PussssyCroook   \n",
       "3  No candidate mentioned  MattFromTexas31   \n",
       "4            Donald Trump       sharonDay5   \n",
       "\n",
       "                                                text sentiment  \n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...   Neutral  \n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive  \n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...   Neutral  \n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...  Positive  \n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['candidate','name', 'text', 'sentiment',]].loc[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how entry 4's *text* field looks like in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @DanScavino: #GOPDebate w/ @realDonaldTrump delivered the highest ratings in the history of presidential debates. #Trump2016 http://t.coâ€¦'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis via LSTM Classifier\n",
    "\n",
    "Let's infer sentiment of texts using Long-Short-Term-Memory (LSTM). We will:\n",
    "1. Preprocessing the data, then prepare the input and output for the network\n",
    "2. Build a network model for classification (model specification)\n",
    "3. Train the network! \n",
    "4. Evaluate the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Preprocess/Data Cleaning**: \n",
    "The first stage is to clean data in a way that the neural network can handle data. \n",
    "- We will perform a binary classification of sentiment: whether the text conveys positive or negative sentiment. Therefore, \n",
    "    - (1) We will extract 2 fields we care about: *text* and *sentiment*. \n",
    "    - (2) We will delete the neutral sentiments from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['text', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets with positive sentiment: 4472\n",
      "Number of tweets with negative sentiment: 16986\n",
      "Number of tweets with neutral sentiment: 0\n"
     ]
    }
   ],
   "source": [
    "data = data[data.sentiment != \"Neutral\"]\n",
    "print(\"Number of tweets with positive sentiment: {}\".format(data[ data['sentiment'] == 'Positive'].size))\n",
    "print(\"Number of tweets with negative sentiment: {}\".format(data[ data['sentiment'] == 'Negative'].size))\n",
    "print(\"Number of tweets with neutral sentiment: {}\".format(data[ data['sentiment'] == 'Neutral'].size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- At the moment, the text field contains a lot of symbols that is not actually part of the message. Also, we don't want to worry too much about case sensitivity. The following code cleans that up abit using **regex** (Don't worry too much about this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  danscavino gopdebate w realdonaldtrump delivered the highest ratings in the history of presidential debates trump2016 httptco'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "data['text'] = data['text'].apply(lambda x: x.replace('rt', ' '))\n",
    "\n",
    "# Let's see how the text got converted\n",
    "data['text'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the text looks better: it just contains all lower case words. There are still random stuff like \"httptco\" and \"w\". It would be very difficult to clean 20000 entries perfectly, so we will decide to live with this. When it affects the network's performance too much, we might come back to clean data further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tokenization\n",
    "- Humans can see a word and understand it, but machines cannot. Everything is just a bunch of numbers to them. Therefore, we need to convert words into a convenient digital representation.\n",
    "- For example, if I want to represent 26 alphabets (a, b, c, ..., x, y, z), we may use the representation (1, 2, 3, ...24, 25, 26) where the correspondance is: (a->1, b->2,...z->26)\n",
    "- For more general words in dictionary, we need more numbers. That's the idea of tokenization. In the following, we will decide the maximum number of features to be 2000. \n",
    "\n",
    "- We will then convert the text into a vectorised form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "43632d2d-6160-12ce-48b0-e5eb1c207076"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b052365fa147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_fatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_fatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "\n",
    "# Let's see how the text is transformed into the representation that machine sees!\n",
    "print(X[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assigned a number to each word! \n",
    "\n",
    "Now, each tweet has different length. It is slightly easier for the network to handle input of the same length. We will \"pad\" the sequence so all tweets have the same number of length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(X)\n",
    "\n",
    "# Let's see how the text is transformed into the representation that machine sees!\n",
    "print(X[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will prepare the output of the network. At the moment, the target variables are 'Positive' and 'Negative'. Again, for the machines, we need a digital representation. We will Positive as [1, 0] and Negative as [0, 1]. This is called *one-hot encoding*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(data['sentiment']).values\n",
    "\n",
    "# Lets see how the output looks like:\n",
    "print(data['sentiment'][4], ' -> ', Y[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input and output are ready!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Building a network\n",
    "\n",
    "Let's build a simple one-layer LSTM network for sentiment classification. We will be using Keras. \n",
    "\n",
    "Our network is composed of 3 components: \n",
    "- **Embedding layer**: The input we prepared above is just a sequence of numbers. This can be processed by the network, but it is not the best representation. For example, \"love\" and \"like\" are words that are similar. We want to be able to represent this \"similarity\" and \"disimilarity\" -- that's precisely the purpose of an embedding layer. In embedding layer, we map the above integers into a *continuous space* where we can define such notion of similarity as a distance metric. This space can have number of dimensions. This is your first hyper-parameter **embed_dim**.\n",
    "- **LSTM layer**: Given the input from embedding layer, we apply LSTM layer to learn hidden representation. hyper-parameter **lstm_out** is the number of hidden units we want to use. Larger the number, more expressive the network gets, but it also becomes more difficult to train this many hidden units.\n",
    "- **Classification layer**: Finally, given the hidden representation computed from the LSTM layer, we perform classification. This takes *lstm_out* number of inputs and map it into binary answer (positive/negative sentiment) via a fully connected layer called *Dense Layer*.\n",
    "\n",
    "Other two hyperparameters are:\n",
    "\n",
    "- **batch_size**: this determines how many number of data point we want to process at the same time. When the batch size is small, the network only learns from specific examples. If the batchsize is large, the network learns from a lot of words simultaneously.  \n",
    "- **droupout_x**: this parameter \"corrupts\" the network randomly. The higher this parameter, more corruption is introduced. By making the network learn while being corrupted, we make the network more robust. \n",
    "\n",
    "These hyperparameters needs to be adjusted to achieve the best performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1ba3cf60-a83c-9c21-05e0-b14303027e93"
   },
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "batchsize = 32\n",
    "dropout_x = 0.2\n",
    "\n",
    "# Build LSTM classifier with 3 components\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(LSTM(lstm_out, dropout=dropout_x, recurrent_dropout=dropout_x))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "15f4ee61-47e4-88c4-4b81-98a85237333f"
   },
   "source": [
    "### Step3: Train the network\n",
    "\n",
    "- From the dataset, we will split into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b35748b8-2353-3db2-e571-5fd22bb93eb0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "\n",
    "print('Size of training data: {}'.format(len(X_train)))\n",
    "print('Size of testing data: {}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2a775979-a930-e627-2963-18557d7bf6e6"
   },
   "source": [
    "- Now we will train the network! Since we don't have too much time, we will train for 5 epochs. Feel free to train for longer :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d5e499ac-2eba-6ff7-8d9a-ff65eb04099b"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs = 5, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4ebd7bc1-53c0-0e31-a0b0-b6d0a3017434"
   },
   "source": [
    "### Step4: Evaluation \n",
    "We will measure the accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a970f412-722f-6d6d-72c8-325d0901ccef"
   },
   "outputs": [],
   "source": [
    "# Measure the overall accuracy on test data\n",
    "_, acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"Overall Accuracy: %.2f\" % (acc))\n",
    "\n",
    "# We will measure the accuracy on positive sentiment class and negative sentiment class\n",
    "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
    "for x in range(len(X_test)):\n",
    "    \n",
    "    result = model.predict(X_test[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "   \n",
    "    if np.argmax(result) == np.argmax(Y_test[x]):\n",
    "        if np.argmax(Y_test[x]) == 0:\n",
    "            neg_correct += 1\n",
    "        else:\n",
    "            pos_correct += 1\n",
    "       \n",
    "    if np.argmax(Y_test[x]) == 0:\n",
    "        neg_cnt += 1\n",
    "    else:\n",
    "        pos_cnt += 1\n",
    "\n",
    "print(\"Accuracy on Positive Sentiment: \", pos_correct/pos_cnt*100, \"%\")\n",
    "print(\"Accuracy on Negative Sentiment: \", neg_correct/neg_cnt*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "018ebf39-9414-27d0-232c-a34de051feaf"
   },
   "source": [
    "### Step 5: Enjoy!\n",
    "\n",
    "Now, define your own tweet and see what the network thinks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "24c64f46-edd1-8d0b-7c7c-ef50fd26b2fd"
   },
   "outputs": [],
   "source": [
    "twt = 'Meetings: Because none of us is as dumb as all of us'\n",
    "\n",
    "# Prepare the input: remember, we need preprocess the data: tokenization and padding. \n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "twt = pad_sequences(twt, maxlen=28, dtype='int32', padding='post', truncating='post', value=0)\n",
    "\n",
    "# Feed the input to the network\n",
    "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
    "\n",
    "# What does network think?\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(\"negative\")\n",
    "elif (np.argmax(sentiment) == 1):\n",
    "    print(\"positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Optimise the network\n",
    "\n",
    "Try adjusting 4 hyper-parameters mentioned: \n",
    "- batchsize \n",
    "- dropout_x \n",
    "- embed_dim \n",
    "- lstm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "1. Why is the accuracy for positive sentiment so much lower than the negative one? There are no wrong answers to this question. Come up with as many reasons as you can. (Hint: for example, look at the number of examples for positive/negative sentiment. Can this be one of the reasons?)\n",
    "2. How did the hyper-parameters affected the performance? How would you improve the network performance further?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 185,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
